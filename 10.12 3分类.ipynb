{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import PIL.Image\n",
    "from torchvision import transforms\n",
    "import  numpy as np\n",
    "import  torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch import  nn\n",
    "from torch import optim\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 数据集预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_file = \"data/01_LungPredictData05.csv\"\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 处理数值类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_file,sep=',')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "all_features = data.iloc[:,:15]\n",
    "outputs  = data.iloc[:,15]\n",
    "\n",
    "strlist = ['sex','inType','outType','recover','fever','pastScore','right_up','right_mid','right_down',\n",
    "           'left_up','left_down']\n",
    "all_features[strlist] = all_features[strlist].astype(np.str)\n",
    "\n",
    "print(all_features.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 若无法获得测试数据，则可根据训练数据计算均值和标准差\n",
    "numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\n",
    "\n",
    "# print(numeric_features[1])\n",
    "# print(all_features[numeric_features])\n",
    "\n",
    "all_features[numeric_features] = all_features[numeric_features].apply(\n",
    "    lambda x: (x - x.mean()) / (x.std()))\n",
    "# 在标准化数据之后，所有均值消失，因此我们可以将缺失值设置为0\n",
    "all_features[numeric_features] = all_features[numeric_features].fillna(0)\n",
    "\n",
    "# “Dummy_na=True”将“na”（缺失值）视为有效的特征值，并为其创建指示符特征\n",
    "all_features = pd.get_dummies(all_features, dummy_na=False)\n",
    "all_features\n",
    "data = pd.concat([all_features,outputs],axis=1)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    ## 数据集输入为inputs 输出为outpus 此时均为Dataframe类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import  openpyxl\n",
    "# xlsx_outputpath='data/after_lungdataset.xlsx'\n",
    "# csv_outputpath='data/after_lungdataset.csv'\n",
    "# all_features.to_excel(xlsx_outputpath,index=True,header=True)\n",
    "# all_features.to_csv(csv_outputpath,sep=',',index=False,header=False)\n",
    "# inputs = all_features\n",
    "# outputs = outputs\n",
    "# data = pd.concat([inputs, outputs], sort=False, axis=1)\n",
    "#\n",
    "# data = pd.read_csv('data/Data.csv',sep=';')\n",
    "#\n",
    "# # 住院时长周数为值\n",
    "# y = data.iloc[:, 48]\n",
    "#\n",
    "# # 定义特征\n",
    "# x = data.iloc[:, 1:48]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(\n",
    "    all_features,outputs, test_size=0.2, random_state=None)\n",
    "X_train = x_train\n",
    "X_test = x_test\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 计算各类总数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # 训练集各类总数\n",
    "# train_class_num_list = [0,0,0]\n",
    "# # double_list = outputs\n",
    "# for id,value in enumerate(y_train):\n",
    "#     if value == 0:\n",
    "#         train_class_num_list[0] = train_class_num_list[0] + 1\n",
    "#     elif value == 1:\n",
    "#         train_class_num_list[1] = train_class_num_list[1] + 1\n",
    "#     else:\n",
    "#         train_class_num_list[2] = train_class_num_list[2] + 1\n",
    "#\n",
    "# # train_np_class_num_list = np.array([train_class_num_list[0],train_class_num_list[1],train_class_num_list[2]])\n",
    "# train_tensor_class_num_list = torch.tensor([train_class_num_list[0],train_class_num_list[1],train_class_num_list[2]])\n",
    "#\n",
    "#\n",
    "# # 测试集各类总数\n",
    "# test_class_num_list = [0,0,0]\n",
    "# # double_list = outputs\n",
    "# for id,value in enumerate(y_test):\n",
    "#     if value == 0:\n",
    "#         test_class_num_list[0] = test_class_num_list[0] + 1\n",
    "#     elif value == 1:\n",
    "#         test_class_num_list[1] = test_class_num_list[1] + 1\n",
    "#     else:\n",
    "#         test_class_num_list[2] = test_class_num_list[2] + 1\n",
    "#\n",
    "#\n",
    "# # train_np_class_num_list = np.array([test_class_num_list[0],test_class_num_list[1],test_class_num_list[2]])\n",
    "# test_tensor_class_num_list = torch.tensor([test_class_num_list[0],test_class_num_list[1],test_class_num_list[2]])\n",
    "#\n",
    "# train_tensor_class_num_list,test_tensor_class_num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#输入\n",
    "x_train = torch.tensor(x_train.values)\n",
    "x_test = torch.tensor(x_test.values)\n",
    "#输出\n",
    "y_train = torch.tensor(y_train.values)\n",
    "y_test = torch.tensor(y_test.values)\n",
    "\n",
    "data_dim = x_train.shape[1]\n",
    "# target_dim = target.shape[1]\n",
    "# print(data)\n",
    "print(data.shape)\n",
    "print(data_dim,x_train.shape)\n",
    "x_train.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 定义Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class LungDataset(Dataset):\n",
    "\n",
    "    def __init__(self,inputs,outputs):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        vector = self.inputs[idx]\n",
    "        label = self.outputs[idx]\n",
    "        return vector,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.outputs)\n",
    "\n",
    "trainDataset = LungDataset(x_train,y_train)\n",
    "testDataset = LungDataset(x_test,y_test)\n",
    "x,y = trainDataset[0]\n",
    "x.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 随机种子\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from torch.backends import cudnn\n",
    "# import random\n",
    "# cudnn.benchmark = False            # if benchmark=True, deterministic will be False\n",
    "# cudnn.deterministic = True\n",
    "#\n",
    "# GLOBAL_SEED = 1\n",
    "#\n",
    "# def set_seed(seed):\n",
    "#     random.seed(seed)\n",
    "#     np.random.seed(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed_all(seed)\n",
    "#\n",
    "# set_seed(1)\n",
    "#\n",
    "# GLOBAL_WORKER_ID = None\n",
    "# def worker_init_fn(worker_id):\n",
    "#     global GLOBAL_WORKER_ID\n",
    "#     GLOBAL_WORKER_ID = worker_id\n",
    "#     set_seed(GLOBAL_SEED + worker_id)\n",
    "# # dataloader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=2, worker_init_fn=worker_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 搭建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_dim = x_train.shape[1]\n",
    "hidden_dim = 10\n",
    "class MnistNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistNet,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim,hidden_dim)  #定义Linear的输入和输出的形状\n",
    "        self.fc2 = nn.Linear(hidden_dim,3)  #定义Linear的输入和输出的形状\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x.view(-1,input_dim)  #对数据形状变形，-1表示该位置根据后面的形状自动调整\n",
    "        x = self.fc1(x) #[batch_size,28]\n",
    "\n",
    "        # x = F.relu(x)  #[batch_size,28]\n",
    "        # x = self.fc1_1(x) #[batch_size,10]\n",
    "\n",
    "        x = F.relu(x)  #[batch_size,28]\n",
    "        x = self.fc2(x) #[batch_size,10]\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# train_dataloader = torch.utils.data.DataLoader(data,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.modules.loss import _Loss\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "\n",
    "\n",
    "class BalancedSoftmax(_Loss):\n",
    "    \"\"\"\n",
    "    Balanced Softmax Loss\n",
    "    \"\"\"\n",
    "    def __init__(self, freq_path):\n",
    "        super(BalancedSoftmax, self).__init__()\n",
    "        with open(freq_path, 'r') as fd:\n",
    "            freq = json.load(fd)\n",
    "        freq = torch.tensor(freq)\n",
    "        self.sample_per_class = freq\n",
    "\n",
    "    def forward(self, input, label, reduction='mean'):\n",
    "        return balanced_softmax_loss(label, input, self.sample_per_class, reduction)\n",
    "\n",
    "\n",
    "def balanced_softmax_loss(labels, logits, sample_per_class, reduction):\n",
    "    \"\"\"Compute the Balanced Softmax Loss between `logits` and the ground truth `labels`.\n",
    "    Args:\n",
    "      labels: A int tensor of size [batch].\n",
    "      logits: A float tensor of size [batch, no_of_classes].\n",
    "      sample_per_class: A int tensor of size [no of classes].\n",
    "      reduction: string. One of \"none\", \"mean\", \"sum\"\n",
    "    Returns:\n",
    "      loss: A float tensor. Balanced Softmax Loss.\n",
    "    \"\"\"\n",
    "    spc = sample_per_class.type_as(logits)\n",
    "\n",
    "    spc = spc.unsqueeze(0).expand(logits.shape[0], -1)\n",
    "\n",
    "    logits = logits + spc.log()\n",
    "\n",
    "    loss = F.cross_entropy(input=logits, target=labels, reduction=reduction)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def create_loss(freq_path):\n",
    "    print('Loading Balanced Softmax Loss.')\n",
    "    return BalancedSoftmax(freq_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 准备迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_batch_size = 64\n",
    "test_batch_size = 128\n",
    "img_size = data_dim\n",
    "\n",
    "def get_dataloader(train=True):\n",
    "\n",
    "    #准备数据集，其中0.1307，0.3081为MNIST数据的均值和标准差，这样操作能够对其进行标准化\n",
    "    #因为MNIST只有一个通道（黑白图片）,所以元组中只有一个值\n",
    "    dataset = trainDataset if train else testDataset\n",
    "    #准备数据迭代器\n",
    "    batch_size = train_batch_size if train else test_batch_size\n",
    "    dataloader = torch.utils.data.DataLoader(dataset,batch_size=batch_size,shuffle=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mnist_net = MnistNet().double()\n",
    "optimizer = optim.Adam(mnist_net.parameters(),lr= 0.001)\n",
    "train_loss_list = []\n",
    "train_count_list = []\n",
    "def train(epoch):\n",
    "    mnist_net.train(True)\n",
    "    train_dataloader = get_dataloader(True)\n",
    "    optimizer.zero_grad()\n",
    "    print(\"开始训练：\")\n",
    "    for idx,(data,target) in enumerate(train_dataloader):\n",
    "        output = mnist_net(data)\n",
    "        # loss = F.cross_entropy(output,target) #对数似然损失\n",
    "        loss = F.nll_loss(output,target) #对数似然损失\n",
    "        # loss = balanced_softmax_loss(labels = target, logits=output, reduction='mean', sample_per_class=train_tensor_class_num_list)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if idx % 200 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch,  idx * len(data), len(train_dataloader.dataset),100. * idx / len(train_dataloader), loss.item()))\n",
    "            train_loss_list.append(loss.item())\n",
    "            train_count_list.append(idx*train_batch_size+(epoch-1)*len(train_dataloader))\n",
    "    print(\"结束训练。\")\n",
    "\n",
    "print(mnist_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def acc_train():\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    mnist_net.eval()\n",
    "    test_dataloader = get_dataloader(train=True)\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_dataloader:\n",
    "            output = mnist_net(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='mean').item()\n",
    "            pred = output.data.max(1, keepdim=True)[1] #获取最大值的位置,[batch_size,1]\n",
    "\n",
    "            # test_loss += balanced_softmax_loss(labels = target,\n",
    "            #                                    logits=(output), reduction='mean',\n",
    "            #                                    sample_per_class=train_tensor_class_num_list).item()\n",
    "            # #output-math.log（）\n",
    "            # spc = test_tensor_class_num_list.type_as(output)\n",
    "            # spc = spc.unsqueeze(0).expand(output.shape[0], -1)\n",
    "            # output = output - spc.log()\n",
    "            # pred = output.data.max(1, keepdim=True)[1] #获取最大值的位置,[batch_size,1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_dataloader.dataset)\n",
    "\n",
    "    print('\\nTrain set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_dataloader.dataset),\n",
    "        100. * correct / len(test_dataloader.dataset)))\n",
    "    correct_rate = 100. * correct / len(test_dataloader.dataset)\n",
    "    return correct_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    mnist_net.eval()\n",
    "    test_dataloader = get_dataloader(train=False)\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_dataloader:\n",
    "            output = mnist_net(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='mean').item()\n",
    "\n",
    "            # test_loss += balanced_softmax_loss(labels = target,\n",
    "            #                                    logits=(output), reduction='mean',\n",
    "            #                                    sample_per_class=test_tensor_class_num_list).item()\n",
    "            #output-math.log（）\n",
    "            # spc = test_tensor_class_num_list.type_as(output)\n",
    "            # spc = spc.unsqueeze(0).expand(output.shape[0], -1)\n",
    "            # output = output - spc.log()\n",
    "\n",
    "            pred = output.data.max(1, keepdim=True)[1] #获取最大值的位置,[batch_size,1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "\n",
    "\n",
    "    test_loss /= len(test_dataloader.dataset)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_dataloader.dataset),\n",
    "        100. * correct / len(test_dataloader.dataset)))\n",
    "    test_correct = 100. * correct / len(test_dataloader.dataset)\n",
    "    return test_correct,test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import PIL\n",
    "epoch = 400\n",
    "#定义两个数组\n",
    "Loss_list = []\n",
    "Accuracy_list = []\n",
    "test_Loss_list = []\n",
    "test_Accuracy_list = []\n",
    "# 训练\n",
    "for i in range(epoch):\n",
    "    train(i)\n",
    "    correct_rate = acc_train()\n",
    "    # Loss_list.append(c)\n",
    "    Accuracy_list.append(correct_rate)\n",
    "\n",
    "    test_correct,test_loss = test()\n",
    "    test_Accuracy_list.append(test_correct)\n",
    "    test_Loss_list.append(test_loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Loss_list = train_loss_list\n",
    "\n",
    "#我这里迭代了200次，所以x的取值范围为(0，200)，然后再将每次相对应的准确率以及损失率附在x上\n",
    "x1 = range(0, epoch)\n",
    "x2 = range(0, epoch)\n",
    "y1 = Accuracy_list\n",
    "y2 = Loss_list\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(x1, y1, 'o-')\n",
    "plt.title('Train accuracy vs. epoches')\n",
    "plt.ylabel('Train accuracy')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(x2, y2, '.-')\n",
    "plt.xlabel('Train loss vs. epoches')\n",
    "plt.ylabel('Train loss')\n",
    "plt.savefig(\"accuracy_loss.jpg\")\n",
    "plt.show()\n",
    "\n",
    "x1 = range(0, epoch)\n",
    "x2 = range(0, epoch)\n",
    "y1 = test_Accuracy_list\n",
    "y2 = test_Loss_list\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(x1, y1, 'o-')\n",
    "plt.title('test accuracy vs. epoches')\n",
    "plt.ylabel('test accuracy')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(x2, y2, '.-')\n",
    "plt.xlabel('test loss vs. epoches')\n",
    "plt.ylabel('test loss')\n",
    "plt.savefig(\"test_accuracy_loss.jpg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.DeepExplainer(mnist_net, torch.from_numpy(X_train.values).double())\n",
    "shap_values = explainer.shap_values(torch.from_numpy(X_test.values).double())\n",
    "shap.summary_plot(shap_values, X_test, plot_type='bar')\n",
    "class_names=[\"1-3 week\",\"3-6week\",\"6+week\"]\n",
    "# shap.summary_plot(shap_values[2], X_test, class_names=class_names)\n",
    "# shap.plots.heatmap(shap_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(mnist_net.state_dict(),\"../mnist_net.pt\") #保存模型参数\n",
    "torch.save(optimizer.state_dict(), '../mnist_optimizer.pt') #保存优化器参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mnist_net.load_state_dict(torch.load(\"../mnist_net.pt\"))\n",
    "optimizer.load_state_dict(torch.load(\"../mnist_optimizer.pt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('bilitorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "557cc881288740aa094b77261477a45d9329eaf2c1519f0f9a24066320bb748e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
